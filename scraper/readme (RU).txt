TwitterScraper
Скрипт для парсинга данных профиля X с использованием библиотеки Playwright. Собирает информацию о подписчиках, количестве твитов и сами твиты с метриками взаимодействия (реплаи, репосты, лайки, просмотры). Результаты сохраняются в JSON-файл.
Возможности
Собирает общую статистику профиля (имя, хендл, подписчики, количество твитов).
Парсит твиты с типом поста (оригинальный, ретвит, цитирование, рекламный).
Извлекает метрики взаимодействия для каждого твита (Reply, Repost, Like, Views).
Логирует процесс в файл scraper.log и консоль.
Поддерживает graceful shutdown при нажатии Ctrl+C.
Требования
Python 3.8+
Установленный Playwright:
bash
pip install playwright
playwright install
Запущенный браузер Chromium с включённым remote debugging port:
bash
chromium --remote-debugging-port=9222
или
bash
google-chrome --remote-debugging-port=9222
Установка
Склонируйте репозиторий или скачайте скрипт:
bash
git clone <URL_репозитория>
cd <папка_репозитория>
Установите зависимости:
bash
pip install playwright
playwright install
Запустите Chromium с открытым портом для отладки и откройте страницу профиля Twitter, которую хотите спарсить (например, https://twitter.com/username):
bash
chromium --remote-debugging-port=9222
Использование
Запустите Chromium с параметром --remote-debugging-port=9222 и заранее откройте в нём страницу профиля Twitter (например, https://twitter.com/username), который хотите спарсить.
Убедитесь, что браузер работает с указанным портом и страница загружена.
Запустите скрипт:
bash
python twitter_scraper.py
Скрипт подключится к браузеру, спарсит данные с открытой страницы и сохранит результат в JSON-файл с именем вида twitter_data_YYYY-MM-DD_HH-MM-SS.json.
Пример вывода
Файл twitter_data_2025-02-24_12-00-00.json:
json
{
    "Имя аккаунта": "User Name",
    "Хендл": "@username",
    "Подписчики": 12300,
    "Количество твитов": 456,
    "Посты": [
        {
            "id": "123456789",
            "Тип поста": "Оригинальный пост",
            "Текст": "Привет, мир!",
            "Дата": "2025-02-23T10:00:00.000Z",
            "Взаимодействия": {
                "Reply": 5,
                "Repost": 10,
                "Like": 50,
                "Views": 1000
            }
        }
    ]
}
Логирование
Логи записываются в файл scraper.log и выводятся в консоль.
Уровень логирования: INFO.
Ошибки и предупреждения также фиксируются для отладки.
Примечания
Скрипт зависит от структуры страницы Twitter на февраль 2025 года. При изменении интерфейса могут потребоваться правки селекторов.
Для работы требуется активная вкладка с профилем Twitter в браузере, открытая заранее.
Если твиты не загружаются, проверьте подключение к интернету или авторизацию в Twitter.
Ограничения
Не поддерживает автоматический вход в аккаунт (нужно быть авторизованным вручную).
Парсит только те данные, которые видны на странице (например, без доступа к скрытым твитам).
Не использует веб-поиск или API, полагается только на открытую страницу.
Устранение неполадок
Ошибка подключения к браузеру: Убедитесь, что Chromium запущен с --remote-debugging-port=9222 и страница профиля Twitter открыта заранее.
Твиты не парсятся: Проверьте селекторы в методе get_tweet_elements() — они могли измениться.
Пустой JSON: Убедитесь, что страница полностью загрузилась перед запуском скрипта.
Лицензия
MIT License. Используйте на свой страх и риск.
Автор
Автор скрипта: MAKO.
README составлен Grok 3 от xAI.